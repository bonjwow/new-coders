---
title: "The Impact of Educational Expenses of New Coders"
subtitle: "The Factors Affecting Education Costs of Beginner Programmers to Learn to Code aside from University Tuition"
author: "Bongju Yoo"
thanks: "https://github.com/bonjwow/new-coders"
date: "`r format(Sys.time(), '%d %B %Y')`"
abstract: ""
output:
  bookdown::pdf_document2:
toc: FALSE
bibliography: references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(stargazer)
library(psych)
# install.packages("here")
library(here)
# install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
# install.packages("QuantPsyc")
library(QuantPsyc)
library(car)
library(kableExtra)
```


```{r, include=FALSE}
# Source: https://stefaneng.github.io/apa_correlation_table/
# install.packages("Hmisc")
library(Hmisc)

apply_if <- function(mat, p, f) {
  # Fill NA with FALSE
  p[is.na(p)] <- FALSE
  mat[p] <- f(mat[p])
  mat
}

apaCorr <- function(mat, corrtype = "pearson") {
  matCorr <- mat
  if (class(matCorr) != "rcorr") {
    matCorr <- rcorr(mat, type = corrtype)
  }
  # Add one star for each p < 0.05, 0.01, 0.001
  stars <- apply_if(round(matCorr$r, 2), matCorr$P < 0.05, function(x) paste0(x, "*"))
  stars <- apply_if(stars, matCorr$P < 0.01, function(x) paste0(x, "*"))
  stars <- apply_if(stars, matCorr$P < 0.001, function(x) paste0(x, "*"))
  # Put - on diagonal and blank on upper diagonal
  stars[upper.tri(stars, diag = T)] <- "-"
  stars[upper.tri(stars, diag = F)] <- ""
  n <- length(stars[1,])
  colnames(stars) <- 1:n
  # Remove _ and convert to title case
  row.names(stars) <- tools::toTitleCase(sapply(row.names(stars), gsub, pattern="_", replacement = " "))
  # Add index number to row names
  row.names(stars) <- paste(paste0(1:n,"."), row.names(stars))
  stars
}
```


# Introduction

With an increasing interest in computer programming and the growth of coding related jobs, more and more people invest their time and money in taking programming courses [@citeHughes]. In this paper, I examine some of the factors that may affect educational expenses of new coders or entry-level programmers aside from university tuition, mainly focusing on the level of education, the size of city, commuting time, income, and learning time. The dataset used for this paper is obtained from freeCodeCamps GitHub page ^[https://github.com/freeCodeCamp/2017-new-coder-survey]. Approximately 20,000 beginner programmers had participated in the survey [@citeSurvey2017].

Firstly, I processed correlation analysis to identify the relationship between each independent variable and dependent variable (education costs) pair and found that all the pairs have a positive linear relationship except for commuting time. Secondly, I used multiple linear regression to determine the statistical significance of the factors. The result of the analysis shows that commuting time is not statistically significant. Interestingly, education background is also not statistically significant associated with educational expenses of beginner programmers. Other variables, such as the size of city, income, and learning time, have a statistical significance on the costs.

This analysis shows that beginner programmers living in small towns and/or low-income households are likely to spend less money on learning to code aside from university tuition than those who live in bigger cities and/or high-income households. It is assumed that there is still a lack of educational resources for new coders living in rural areas and/or low-income households. Free online learning platforms such as freeCodeCamp can be a great resource of education for the coders.

The paper is organized as follows. The Data section describes features of the original survey data and how the data is preprocessed. The Model section explains the multiple linear regression model used to assess the association between each factor and educational costs of beginner programmers, and evaluates the model using its residual standard error, multiple R-squared, and F-statistic. The Results section summarises the results of the regression model and model evaluation processes in the Model section. Lastly, the Discussion section discusses the findings and potential limitations of the paper, and suggests directions for future research related to this data.

# Data
```{r, include=FALSE}
#### TODO's ####
# Explain raw data 
# Discuss the variables
#
```


```{r}
#### Message to Reviewers ####
#
# Code chunks are visible on the PDF for the review.
# Any comments or suggestions are welcome to improve this paper :D
#
# // Variables
# Y: MoneyForLearning
# X: Age, CityPopulation, CommuteTime, Income, MonthsProgramming, SchoolDegree
# c: Gender
# 

#### Get data ####
dfNewCoders <- 
  readr::read_csv(here::here("inputs/data/clean_new-coders.csv"))

```


```{r, echo=FALSE, warning=FALSE, message=FALSE}
#### Descriptive statistics ####
stargazer::stargazer(data.frame(dfNewCoders), type = "text")

```


```{r, echo=FALSE, warning=FALSE, message=FALSE}
#### Correlation analysis ####

### Print correlation coefficient
tblCorr <-
  dfNewCoders %>%
  as.matrix() %>%
  apaCorr() %>%
  data.frame() %>%
  kable(caption = "Correlation matrix for variables",
        booktabs = TRUE,
        col.names = c("1", "2", "3", "4", "5", "6", "7", "8")) %>%
  footnote(general = "* p < 0.05, ** p < 0.01, *** p < 0.001",
             general_title = "")

tblCorr

```



```{r}
### Print correlation matrix
PerformanceAnalytics::chart.Correlation(dfNewCoders, 
                                        histogram = TRUE, 
                                        pch = 19)
```


# Model
```{r, include=FALSE}
#### TODO's ####
# Write out what each variable is
# Weaknesses and next steps
```


```{r, results='asis'}
#### Multiple regression analysis ####
fit.lm <- lm(formula = 
               MoneyForLearning ~ 
               Gender +
               CityPopulation +
               CommuteTime +
               Income +
               MonthsProgramming +
               SchoolDegree, 
               data = dfNewCoders)


# summary(fit.lm)
stargazer::stargazer(fit.lm, 
          title = "Result of regression model", 
          header = FALSE,
          type = "latex")
```




```{r}
#### Beta ####
QuantPsyc::lm.beta(fit.lm)
```



```{r}
#### Check multicollinearity with Variance Inflation Factor (VIF) & Tolerance ####

### VIF
car::vif(fit.lm)
### Tolerance
1/car::vif(fit.lm)
```

```{r}
# TODO: RMSE
```



# Results

# Discussion
```{r, include=FALSE}
#### TODO's ####
# Write at least 2.5 pages for the Discussion section
# Weaknesses and next steps
```


\newpage

# Appendix {-}

\newpage


# References


